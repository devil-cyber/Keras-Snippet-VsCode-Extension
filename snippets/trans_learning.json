{
 "Keras-2.2.5 Transrfer Learning Inception-Net V3":{
     "prefix":"!inception-v3",
     "body":[
         "# Note : This is a boilerplate for how to used transfer learning with your own dataset",
         "# Fell free to change the parameter according to your use cases",
         "# For more visit : https://keras.io/api/applications/",
         "import tensorflow as tf",
         "from keras.models import Sequential",
         "from tensorflow.keras import layers",
         "from keras.layers.normalization import BatchNormalization",
         "from keras.preprocessing.image import ImageDataGenerator",
         "from keras.layers import Dense,Input,Concatenate,Embedding,Dropout,Flatten",
         "from keras.applications.inception_v3 import InceptionV3",
         "\n",
         "# Minimum Image size required by InceptionV3 is 75 X 75",
        "conv_base=InceptionV3(weights='imagenet',include_top=False,input_shape=(75,75,3))",
        "# This code will prevent the model to retrain the imagenet wight",
        "for layer in conv_base.layers:",
        "    layer.trainable=False",
        "\n",
        "\n",
        "classifier = Sequential()",
        "classifier.add(conv_base)",
        "classifier.add(Flatten())",
        "classifier.add(Dropout(.4))",
        "classifier.add(Dense(64,activation='relu'))",
        "classifier.add(BatchNormalization())",
        "classifier.add(Dense('Your Class',activation='softmax'))",
        "classifier.add(BatchNormalization())",
        "\n",
        "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])",
        "\n",
        "train_data = ImageDataGenerator(rescale=1. / 255)",
        "test_data = ImageDataGenerator(rescale=1./255)",
        "\n",
        "training_set = train_data.flow_from_directory('dataset path',target_size=(75,75))",
        "test_set = train_data.flow_from_directory('dataset path',target_size=(75,75))",
        "history = classifier.fit(training_set,epochs=10,steps_per_epoch =500,validation_data = test_set,validation_steps=50,shuffle=True,verbose=1)",
        "history.save('model_8_1_1_class.h5')",
        "print(test_set.class_indices)",
        "print('Saved model to disk')"


     ]
 },
 "Keras-2.2.5 Transrfer Learning VGG16":{
    "prefix":"!vgg16",
    "body":[
        "# Note : This is a boilerplate for how to used transfer learning with your own dataset",
        "# Fell free to change the parameter according to your use cases",
        "# For more visit : https://keras.io/api/applications/",
        "import tensorflow as tf",
        "from keras.models import Sequential",
        "from tensorflow.keras import layers",
        "from keras.layers.normalization import BatchNormalization",
        "from keras.preprocessing.image import ImageDataGenerator",
        "from keras.layers import Dense,Input,Concatenate,Embedding,Dropout,Flatten",
        "from keras.applications.vgg16 import VGG16",
        "\n",
        "# Minimum Image size required by InceptionV3 is 75 X 75",
       "conv_base=VGG16(weights='imagenet',include_top=False,input_shape=(75,75,3))",
       "# This code will prevent the model to retrain the imagenet wight",
       "for layer in conv_base.layers:",
       "    layer.trainable=False",
       "\n",
       "\n",
       "classifier = Sequential()",
       "classifier.add(conv_base)",
       "classifier.add(Flatten())",
       "classifier.add(Dropout(.4))",
       "classifier.add(Dense(64,activation='relu'))",
       "classifier.add(BatchNormalization())",
       "classifier.add(Dense('Your Class',activation='softmax'))",
       "classifier.add(BatchNormalization())",
       "\n",
       "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])",
       "\n",
       "train_data = ImageDataGenerator(rescale=1. / 255)",
       "test_data = ImageDataGenerator(rescale=1./255)",
       "\n",
       "training_set = train_data.flow_from_directory('dataset path',target_size=(75,75))",
       "test_set = train_data.flow_from_directory('dataset path',target_size=(75,75))",
       "history = classifier.fit(training_set,epochs=10,steps_per_epoch =500,validation_data = test_set,validation_steps=50,shuffle=True,verbose=1)",
       "history.save('model_8_1_1_class.h5')",
       "print(test_set.class_indices)",
       "print('Saved model to disk')"


    ]
},
"Keras-2.2.5 Transrfer Learning VGG19":{
    "prefix":"!vgg19",
    "body":[
        "# Note : This is a boilerplate for how to used transfer learning with your own dataset",
        "# Fell free to change the parameter according to your use cases",
        "# For more visit : https://keras.io/api/applications/",
        "import tensorflow as tf",
        "from keras.models import Sequential",
        "from tensorflow.keras import layers",
        "from keras.layers.normalization import BatchNormalization",
        "from keras.preprocessing.image import ImageDataGenerator",
        "from keras.layers import Dense,Input,Concatenate,Embedding,Dropout,Flatten",
        "from keras.applications.vgg19 import VGG19",
        "\n",
        "# Minimum Image size required by InceptionV3 is 75 X 75",
       "conv_base=VGG19(weights='imagenet',include_top=False,input_shape=(75,75,3))",
       "# This code will prevent the model to retrain the imagenet wight",
       "for layer in conv_base.layers:",
       "    layer.trainable=False",
       "\n",
       "\n",
       "classifier = Sequential()",
       "classifier.add(conv_base)",
       "classifier.add(Flatten())",
       "classifier.add(Dropout(.4))",
       "classifier.add(Dense(64,activation='relu'))",
       "classifier.add(BatchNormalization())",
       "classifier.add(Dense('Your Class',activation='softmax'))",
       "classifier.add(BatchNormalization())",
       "\n",
       "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])",
       "\n",
       "train_data = ImageDataGenerator(rescale=1. / 255)",
       "test_data = ImageDataGenerator(rescale=1./255)",
       "\n",
       "training_set = train_data.flow_from_directory('dataset path',target_size=(75,75))",
       "test_set = train_data.flow_from_directory('dataset path',target_size=(75,75))",
       "history = classifier.fit(training_set,epochs=10,steps_per_epoch =500,validation_data = test_set,validation_steps=50,shuffle=True,verbose=1)",
       "history.save('model_8_1_1_class.h5')",
       "print(test_set.class_indices)",
       "print('Saved model to disk')"


    ]
},
"Keras-2.2.5 Transrfer Learning ResNet50":{
    "prefix":"!resnet-50",
    "body":[
        "# Note : This is a boilerplate for how to used transfer learning with your own dataset",
        "# Fell free to change the parameter according to your use cases",
        "# For more visit : https://keras.io/api/applications/",
        "import tensorflow as tf",
        "from keras.models import Sequential",
        "from tensorflow.keras import layers",
        "from keras.layers.normalization import BatchNormalization",
        "from keras.preprocessing.image import ImageDataGenerator",
        "from keras.layers import Dense,Input,Concatenate,Embedding,Dropout,Flatten",
        "from keras.applications.resnet50 import ResNet50",
        "\n",
        "# Minimum Image size required by InceptionV3 is 75 X 75",
       "conv_base=ResNet50(weights='imagenet',include_top=False,input_shape=(75,75,3))",
       "# This code will prevent the model to retrain the imagenet wight",
       "for layer in conv_base.layers:",
       "    layer.trainable=False",
       "\n",
       "\n",
       "classifier = Sequential()",
       "classifier.add(conv_base)",
       "classifier.add(Flatten())",
       "classifier.add(Dropout(.4))",
       "classifier.add(Dense(64,activation='relu'))",
       "classifier.add(BatchNormalization())",
       "classifier.add(Dense('Your Class',activation='softmax'))",
       "classifier.add(BatchNormalization())",
       "\n",
       "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])",
       "\n",
       "train_data = ImageDataGenerator(rescale=1. / 255)",
       "test_data = ImageDataGenerator(rescale=1./255)",
       "\n",
       "training_set = train_data.flow_from_directory('dataset path',target_size=(75,75))",
       "test_set = train_data.flow_from_directory('dataset path',target_size=(75,75))",
       "history = classifier.fit(training_set,epochs=10,steps_per_epoch =500,validation_data = test_set,validation_steps=50,shuffle=True,verbose=1)",
       "history.save('model_8_1_1_class.h5')",
       "print(test_set.class_indices)",
       "print('Saved model to disk')"


    ]
},
"Keras-2.2.5 Transrfer Learning Xception-Net":{
    "prefix":"!xception",
    "body":[
        "# Note : This is a boilerplate for how to used transfer learning with your own dataset",
        "# Fell free to change the parameter according to your use cases",
        "# For more visit : https://keras.io/api/applications/",
        "import tensorflow as tf",
        "from keras.models import Sequential",
        "from tensorflow.keras import layers",
        "from keras.layers.normalization import BatchNormalization",
        "from keras.preprocessing.image import ImageDataGenerator",
        "from keras.layers import Dense,Input,Concatenate,Embedding,Dropout,Flatten",
        "from keras.applications.xception import Xception",
        "\n",
        "# Minimum Image size required by InceptionV3 is 75 X 75",
       "conv_base=Xception(weights='imagenet',include_top=False,input_shape=(75,75,3))",
       "# This code will prevent the model to retrain the imagenet wight",
       "for layer in conv_base.layers:",
       "    layer.trainable=False",
       "\n",
       "\n",
       "classifier = Sequential()",
       "classifier.add(conv_base)",
       "classifier.add(Flatten())",
       "classifier.add(Dropout(.4))",
       "classifier.add(Dense(64,activation='relu'))",
       "classifier.add(BatchNormalization())",
       "classifier.add(Dense('Your Class',activation='softmax'))",
       "classifier.add(BatchNormalization())",
       "\n",
       "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])",
       "\n",
       "train_data = ImageDataGenerator(rescale=1. / 255)",
       "test_data = ImageDataGenerator(rescale=1./255)",
       "\n",
       "training_set = train_data.flow_from_directory('dataset path',target_size=(75,75))",
       "test_set = train_data.flow_from_directory('dataset path',target_size=(75,75))",
       "history = classifier.fit(training_set,epochs=10,steps_per_epoch =500,validation_data = test_set,validation_steps=50,shuffle=True,verbose=1)",
       "history.save('model_8_1_1_class.h5')",
       "print(test_set.class_indices)",
       "print('Saved model to disk')"


    ]
}
}